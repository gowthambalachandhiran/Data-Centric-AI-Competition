{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_centric_AI_ConditionalGans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_pYMOrxrAhs"
      },
      "source": [
        "# Generative Adversarial Network for an MNIST Handwritten Digits From Scratch in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXegb27bQZxk"
      },
      "source": [
        "from numpy import asarray\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sacCVkucOBPo"
      },
      "source": [
        "!rm -rf /content/trainImage\n",
        "!rm -rf /content/training_checkpoints/*\n",
        "!rm -rf /content/trainImages/.DS_Store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_PTUnbROYa"
      },
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import os, shutil\n",
        "from os import listdir\n",
        "## Image Resizing\n",
        "from PIL import Image\n",
        "\n",
        "# load and display an image with Matplotlib\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuuYoEfkRQGY",
        "outputId": "a98b3996-e0db-4a12-dcd2-b5311154ab2f"
      },
      "source": [
        "# Image folder\n",
        "images_dir = Path('/content/trainImage').expanduser()\n",
        "images_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/trainImage')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOkY14iFRuXR"
      },
      "source": [
        "dim = (28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oputOMMTRuc_"
      },
      "source": [
        "# Resizing all the images to same dimension\n",
        "X_image_train = []\n",
        "for fname in listdir(images_dir):\n",
        "    fpath = os.path.join(images_dir, fname)\n",
        "    im = Image.open(fpath)\n",
        "   \n",
        "    im_resized = im.resize(dim)\n",
        "    \n",
        "    X_image_train.append(im_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h95_iZlQSRTJ"
      },
      "source": [
        "## Converting the image to numpy array\n",
        "X_image_array=[]\n",
        "for x in range(len(X_image_train)):\n",
        "\n",
        "    X_image=np.array(X_image_train[x],dtype='uint8')\n",
        "    X_image = (X_image // 43) * 43\n",
        "    X_image[X_image > 43] = 255\n",
        "    X_image_array.append(X_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXN6ViH-SX9i"
      },
      "source": [
        "X_image_array= np.stack(X_image_array) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLPqq3j-SZ7w",
        "outputId": "715c6821-d722-418d-a33c-b64cc6f5053a"
      },
      "source": [
        "X_image_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1124, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "IR3NVz1KrAhy",
        "outputId": "3440b317-162f-48d1-bcb6-71ff28881b73"
      },
      "source": [
        "#plot of 25 images from the MNIST training dataset, arranged in a 5Ã—5 square.\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from matplotlib import pyplot\n",
        "matplotlib.use('TkAgg')\n",
        "# load the images into memory\n",
        "#(trainX, trainy), (testX, testy) = load_data()\n",
        "# plot images from the training dataset\n",
        "for i in range(25):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(5, 5, 1 + i)\n",
        "\t# turn off axis\n",
        "\tpyplot.axis('off')\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(X_image_array[i],cmap='gray')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uznHXAq8rAhz"
      },
      "source": [
        "\n",
        "##  MNIST dataset to train the generator and the discriminator. The generator will generate Unique handwritten digits resembling the MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYrm0q6qrAhz"
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVPghJc1rAh0"
      },
      "source": [
        "train_images = X_image_array.reshape(X_image_array.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzOzoNK5VT3F",
        "outputId": "aa5ede7b-37fc-4cbc-e2aa-8372f7477722"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1124, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRl3BIO4rAh0"
      },
      "source": [
        "BUFFER_SIZE = 6000\n",
        "BATCH_SIZE = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx9wmVG8rAh1"
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB3r1okprAh1"
      },
      "source": [
        "# The Generator\n",
        "\n",
        "The generator uses <b>tf.keras.layers.Conv2DTranspose (upsampling) layers </b> to produce an image from a random noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuKmqdOVrAh2"
      },
      "source": [
        "# input 7*7*256 (low resolution version of the output image)\n",
        "# outputs a single 28Ã—28 grayscale image\n",
        "# this generator takes a vector of size 100 and first reshape that into (7, 7, 128) vector then applied transpose \n",
        "# convolution in combination with batch normalization. \n",
        "\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "   # upsample to 14x14\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    # upsample to 28x28\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIq8xf_rrAh2"
      },
      "source": [
        "# Use the (as yet untrained) generator to create an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "DmKFqaC0rAh3",
        "outputId": "7e009293-23db-402e-c489-3303d4c7f1aa"
      },
      "source": [
        "# sample image generated by the the generator\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.uniform([1, 100]) #latent space\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0] ,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3f00271210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8buJ9_corAh3"
      },
      "source": [
        "# The Discriminator\n",
        "### The discriminator is a CNN-based image classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cec37BTjrAh3"
      },
      "source": [
        "# Input to discriminator = 28*28*1   grayscale image\n",
        "# Output  binary prediction (image is real (class=1) or fake (class=0))\n",
        "# no pooling layers  \n",
        "# single node in the output layer with the sigmoid activation function to predict whether the input sample is real or fake. \n",
        "# Downsampling from 28Ã—28 to 14Ã—14, then to 7Ã—7, before the model makes an output prediction\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[28, 28, 1])) #2Ã—2 stride to downsample\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')) #downsampling  2Ã—2 stride to downsample\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())  # classifier real (class=1) or fake (class=0))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7orsZORrAh4"
      },
      "source": [
        "###  Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFl3K8IYrAh4",
        "outputId": "87471540-7a9e-463b-d8c0-e0b431c86e31"
      },
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.5002953]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk_iq0JorAh5"
      },
      "source": [
        "# Define the loss and optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLcr0wlnrAh5"
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkPMMJGgrAh5"
      },
      "source": [
        "# Discriminator loss\n",
        "\n",
        "#### This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcOO8RFprAh6"
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pfIfVdLrAh6"
      },
      "source": [
        "# Generator loss\n",
        "\n",
        "### The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCO_sNDTrAh6"
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZThEfSrarAh6"
      },
      "source": [
        "### The discriminator and the generator optimizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb2m5U9grAh7"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhkCZvrAh7"
      },
      "source": [
        "# Save checkpoints\n",
        "This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHd49WkrAh7"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBYtdbi3rAh7"
      },
      "source": [
        "# Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRSjGnq0rAh7"
      },
      "source": [
        "EPOCHS = 2000\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEKD9HXrAh8"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-VKC_yjrAh8"
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8y0VAl2rAh9"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hV-TODYrAh9"
      },
      "source": [
        "# Generate and save images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJwiv0VIrAh9"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBbejvGmrAh9"
      },
      "source": [
        "# Train the model\n",
        "Call the train() method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
        "\n",
        "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fMUlrwnK3Ert",
        "outputId": "e7ec2a78-2f77-4c0b-a209-d17c66fd9bb4"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAD7klEQVR4nO3asU7rWBRA0evRfBEVokp+ABKKfA1NqpR88p3qNU+j4EhEZpO1JFe4OAd7x0F4mXMOoOGfrQcA1hMshAgWQgQLIYKFkKvBLssyj8fjHGNUj1WWZZn7/X7rWe++559dy8cte769vW19Xb79ml4N9nA4jOfn5zW/n7Tdbjd2u93WY/CNXl9fx8vLy9ZjfLvli//D3vTp/QMtK897lD3HLU+pn2jO+dDX1N+wECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyHLnHPrGYCVPGEhRLAQIlgIESyECBZCBAshgoUQwULI1WD3+/08n89zjFE9Vjkej/NyuWw96933HGOMZVlm+Vi75+Fw+JXX9Ks3nW66GX6gZeV5j7LnuOWm/4nmnA99TX0lhhDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAhZ5pxbzwCs5AkLIYKFEMFCiGAhRLAQIlgIESyECBZCBAsh/1774bIs6deg5pzLmvPe39/n09PT+Pj4uPdI97JqzzEe55r+1j2vvpr4W5f+v1PvOsj9CfYvv3VPX4khRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQpY559YzACt5wkKIYCFEsBAiWAgRLIQIFkIECyGChRDBQsjVYI/H47xcLnOMUT1W2e/383w+bz3r3fccY4zT6fQQu55Op/n5+bn1rN++51evJt50M/xAy8rzHmXPMR5n11+5p6/EECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyHLnHPrGYCVPGEhRLAQIlgIESyECBZCBAsh/wFiqaNc5smBQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUwmEKShrAh-"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X35-j18rAh-"
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjkdlg-OrAiA"
      },
      "source": [
        "the latent space is just where you pick the noise from(to give to the generator) \n",
        "The generator model in the GAN architecture takes a point from the latent space as input and generates a new image.\n",
        "\n",
        "The latent space is a 100-dimensional space with random points. points in the latent space can be constructed (e.g. all 0s, all 0.5s, or all 1s) \n",
        "New images are generated using random points in the latent space.\n",
        "Points in the latent space used as input or a query to generate a specific image.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}